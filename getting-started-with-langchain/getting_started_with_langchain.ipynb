{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Introduction"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T16:19:09.919882Z",
     "start_time": "2024-12-17T16:19:09.724829Z"
    }
   },
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "langchain_api_key = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "langchain_project = os.getenv(\"LANGCHAIN_PROJECT\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T16:19:40.841980Z",
     "start_time": "2024-12-17T16:19:40.837539Z"
    }
   },
   "cell_type": "code",
   "source": "print(openai_api_key)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T18:01:37.178362Z",
     "start_time": "2024-12-17T18:01:14.276478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "  os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter API key for OpenAI: \")\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.invoke(\"Hello World\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading Documents"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## From word documents"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T06:33:00.446306Z",
     "start_time": "2024-12-18T06:33:00.430824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(os.getcwd())\n",
    "print(os.listdir())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\George\\Documents\\projects-2025\\generative-ai-with-langchain\\getting-started-with-langchain\n",
      "['.ipynb_checkpoints', 'credentials.json', 'data', 'getting_started_with_langchain.ipynb']\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T06:33:08.715632Z",
     "start_time": "2024-12-18T06:33:08.705244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import Docx2txtLoader\n",
    "\n",
    "loader = Docx2txtLoader(\"data/Module 1 Storyboard/Module 1 .docx\")"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "docs = loader.load()\n",
    "print(docs)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T06:53:09.509050Z",
     "start_time": "2024-12-18T06:53:09.494938Z"
    }
   },
   "cell_type": "code",
   "source": "type(docs)",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Transformation\n",
    "\n",
    "Converting Documents into chunks of text\n",
    "*Using RecursiveCharacterTextSplitter*"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T09:21:31.556695Z",
     "start_time": "2024-12-18T09:21:31.532403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "try:\n",
    "  splitter = RecursiveCharacterTextSplitter(chunk_size=900, chunk_overlap=100)\n",
    "  final_docs = splitter.split_documents(documents=docs)\n",
    "  print(final_docs[123])\n",
    "  print(final_docs[124])\n",
    "except IndexError as e:\n",
    "  print(\"The chunk size is too large\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Write the label on each medicine, giving precise direction for use.\n",
      "\n",
      "Put the medicines in the dispensing vial and place the label on the vial.\n",
      "\n",
      "Check the dispensing medicine and confirm that the medicine is what was prescribed.\n",
      "\n",
      "Hand the dispensed medicine to the patient or care giver/patientâ€™s relation. \n",
      "\n",
      "Counsel the patient giving details on how the medicine should be used.\n",
      "\n",
      "Give the patient a chance to ask questions and give the patient appropriate answers\n",
      "\n",
      "Thank the patient as they leave and keep all patient medication records\n",
      "\n",
      "Below is an example of a good medication label:\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Click to continue\n",
      "\n",
      "End of Screen/ Section\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Screen/ Section Type: Static with text\n",
      "\n",
      "\n",
      "\n",
      "#\n",
      "\n",
      "On Screen/ Section Content\n",
      "\n",
      "\n",
      "\n",
      "Topic' metadata={'source': 'data/Module 1 Storyboard/Module 1 .docx'}\n",
      "page_content='Screen/ Section Type: Static with text\n",
      "\n",
      "\n",
      "\n",
      "#\n",
      "\n",
      "On Screen/ Section Content\n",
      "\n",
      "\n",
      "\n",
      "Topic \n",
      "\n",
      "Respectful Pharmacy Practices Linking Supply Chain and Customer Service- Knowledge Check\n",
      "\n",
      "#\n",
      "\n",
      "On Screen Content\n",
      "\n",
      "\tDesign Notes\t\n",
      "\n",
      "\n",
      "\n",
      "ST: Session Recap\n",
      "\n",
      "Congratulations! You have come to the end of Respectful Pharmacy Practices Linking Supply Chain and Customer Service\n",
      "\n",
      "\n",
      "\n",
      "We have learnt why it is critical to have customer satisfaction at the centre of steps such as product selection, procurement, warehouse and distribution can lead to efficient supply chains.\n",
      "\n",
      "\n",
      "\n",
      "The ability to understand and cater to the diverse behaviours of customers who visit the pharmacy can be one of the key factors leading to better health outcomes.\n",
      "\n",
      "\n",
      "\n",
      "Applying patient-centred communication such as openness, active listening, and plain speaking are among the best practices at the pharmacy in serving the customer.' metadata={'source': 'data/Module 1 Storyboard/Module 1 .docx'}\n"
     ]
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Converting Documents into chunks of text Using *CharacterTextSplitter*"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "splitter = CharacterTextSplitter(chunk_size=900, chunk_overlap=100)\n",
    "final_docs = splitter.split_documents(documents=docs)\n",
    "print(final_docs[123])\n",
    "print(final_docs[124])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Embeddings\n",
    "\n",
    "Converting the text chunks into vectors - a numerical form\n",
    "\n",
    "Using embedding models (techniques)\n",
    "\n",
    "- openAI (paid)\n",
    "- Ollama (open source)\n",
    "- Hugging Face (open source)\n",
    "\n",
    "Embeddings are a numerical representation of text that can be used to measure the relatedness between two pieces of text. Embeddings are useful for search, clustering, recommendations, anomaly detection, and classification tasks."
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings(api_key=openai_api_key, model=\"text-embedding-3-large\")\n",
    "embeddings"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# test embedding\n",
    "text = \"This is a very interesting tutorial\"\n",
    "embedding_test_results = embeddings.embed_query(text=text)\n",
    "print(embedding_test_results)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T09:20:21.269354Z",
     "start_time": "2024-12-18T09:20:21.263311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(embedding_test_results[0])\n",
    "\n",
    "len(embedding_test_results)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.016360953450202942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-18T09:27:40.614615Z",
     "start_time": "2024-12-18T09:27:40.309574Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Embed final docs and store in a vector database\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "db = Chroma.from_documents(documents=docs, embedding=embeddings)"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import chromadb python package. Please install it with `pip install chromadb`.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[1;32m~\\Documents\\projects_2024\\Generative-AI-With-Langchain\\venv\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:83\u001B[0m, in \u001B[0;36mChroma.__init__\u001B[1;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001B[0m\n\u001B[0;32m     82\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 83\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mchromadb\u001B[39;00m\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mchromadb\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconfig\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'chromadb'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[69], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Embed final docs and store in a vector database\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_community\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mvectorstores\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Chroma\n\u001B[1;32m----> 4\u001B[0m db \u001B[38;5;241m=\u001B[39m \u001B[43mChroma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_documents\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdocuments\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdocs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43membeddings\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\projects_2024\\Generative-AI-With-Langchain\\venv\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:887\u001B[0m, in \u001B[0;36mChroma.from_documents\u001B[1;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001B[0m\n\u001B[0;32m    885\u001B[0m texts \u001B[38;5;241m=\u001B[39m [doc\u001B[38;5;241m.\u001B[39mpage_content \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m documents]\n\u001B[0;32m    886\u001B[0m metadatas \u001B[38;5;241m=\u001B[39m [doc\u001B[38;5;241m.\u001B[39mmetadata \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m documents]\n\u001B[1;32m--> 887\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_texts\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    888\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtexts\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtexts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    889\u001B[0m \u001B[43m    \u001B[49m\u001B[43membedding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    890\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmetadatas\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadatas\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    891\u001B[0m \u001B[43m    \u001B[49m\u001B[43mids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    892\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcollection_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollection_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    893\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpersist_directory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpersist_directory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    894\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclient_settings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclient_settings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    895\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    896\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcollection_metadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollection_metadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    897\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    898\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\projects_2024\\Generative-AI-With-Langchain\\venv\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:817\u001B[0m, in \u001B[0;36mChroma.from_texts\u001B[1;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001B[0m\n\u001B[0;32m    784\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[0;32m    785\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfrom_texts\u001B[39m(\n\u001B[0;32m    786\u001B[0m     \u001B[38;5;28mcls\u001B[39m: Type[Chroma],\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    796\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any,\n\u001B[0;32m    797\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Chroma:\n\u001B[0;32m    798\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Create a Chroma vectorstore from a raw documents.\u001B[39;00m\n\u001B[0;32m    799\u001B[0m \n\u001B[0;32m    800\u001B[0m \u001B[38;5;124;03m    If a persist_directory is specified, the collection will be persisted there.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    815\u001B[0m \u001B[38;5;124;03m        Chroma: Chroma vectorstore.\u001B[39;00m\n\u001B[0;32m    816\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 817\u001B[0m     chroma_collection \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    818\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcollection_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollection_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    819\u001B[0m \u001B[43m        \u001B[49m\u001B[43membedding_function\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43membedding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    820\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpersist_directory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpersist_directory\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    821\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclient_settings\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclient_settings\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    822\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    823\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcollection_metadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollection_metadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    825\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    826\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ids \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    827\u001B[0m         ids \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mstr\u001B[39m(uuid\u001B[38;5;241m.\u001B[39muuid4()) \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m texts]\n",
      "File \u001B[1;32m~\\Documents\\projects_2024\\Generative-AI-With-Langchain\\venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:216\u001B[0m, in \u001B[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    214\u001B[0m     warned \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    215\u001B[0m     emit_warning()\n\u001B[1;32m--> 216\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\projects_2024\\Generative-AI-With-Langchain\\venv\\Lib\\site-packages\\langchain_community\\vectorstores\\chroma.py:86\u001B[0m, in \u001B[0;36mChroma.__init__\u001B[1;34m(self, collection_name, embedding_function, persist_directory, client_settings, collection_metadata, client, relevance_score_fn)\u001B[0m\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mchromadb\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconfig\u001B[39;00m\n\u001B[0;32m     85\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[1;32m---> 86\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[0;32m     87\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not import chromadb python package. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     88\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease install it with `pip install chromadb`.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     89\u001B[0m     )\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m client \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     92\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client_settings \u001B[38;5;241m=\u001B[39m client_settings\n",
      "\u001B[1;31mImportError\u001B[0m: Could not import chromadb python package. Please install it with `pip install chromadb`."
     ]
    }
   ],
   "execution_count": 69
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
